{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WSN-IDS: Machine Learning Based Intrusion Detection for Wireless Sensor Networks\n",
    "\n",
    "This notebook walks through the full pipeline:\n",
    "1. Dataset generation & exploration\n",
    "2. Feature engineering\n",
    "3. Model training (Random Forest, Decision Tree, KNN, SVM, MLP)\n",
    "4. Evaluation (Accuracy, Precision, Recall, F1, FPR, Energy Impact)\n",
    "5. Visualisations\n",
    "6. Real-time inference demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "\n",
    "from wsn_ids import ATTACK_LABELS, FEATURE_NAMES\n",
    "print('Imports OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wsn_ids.data.generate_dataset import generate_dataset\n",
    "from wsn_ids.features.feature_extraction import add_derived_features\n",
    "\n",
    "df_raw = generate_dataset(samples_per_class=500, save_path='../results/wsn_dataset.csv')\n",
    "df = add_derived_features(df_raw)\n",
    "\n",
    "print(f'Dataset shape : {df.shape}')\n",
    "print(f'\\nClass counts:')\n",
    "print(df['attack_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from wsn_ids.visualization.plots import (\n",
    "    plot_class_distribution,\n",
    "    plot_feature_distributions,\n",
    "    plot_correlation_heatmap,\n",
    "    plot_pca_scatter,\n",
    ")\n",
    "\n",
    "Path('../results/plots').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "all_features = list(FEATURE_NAMES) + [\n",
    "    'energy_efficiency_index', 'traffic_anomaly_score', 'identity_confusion_index'\n",
    "]\n",
    "available = [f for f in all_features if f in df.columns]\n",
    "\n",
    "plot_class_distribution(df, save_dir='../results/plots')\n",
    "plot_feature_distributions(df, features=available, save_dir='../results/plots')\n",
    "plot_correlation_heatmap(df, features=available, save_dir='../results/plots')\n",
    "\n",
    "print('EDA plots saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display class distribution inline\n",
    "matplotlib.use('Agg')\n",
    "img = mpimg.imread('../results/plots/class_distribution.png')\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/tmp/display_class.png', dpi=100)\n",
    "plt.close()\n",
    "print('Plot saved to /tmp/display_class.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering & Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wsn_ids.features.feature_extraction import split_dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test, feature_cols = split_dataset(df, test_size=0.20)\n",
    "\n",
    "print(f'Training samples : {len(X_train)}')\n",
    "print(f'Test samples     : {len(X_test)}')\n",
    "print(f'Features used    : {feature_cols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derived feature stats\n",
    "derived = ['energy_efficiency_index', 'traffic_anomaly_score', 'identity_confusion_index']\n",
    "df.groupby('attack_type')[derived].mean().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wsn_ids.models.train import build_models, train_all, save_models\n",
    "\n",
    "models = build_models(random_state=42)\n",
    "print('Training models ...')\n",
    "train_all(models, X_train, y_train)\n",
    "save_models(models, save_dir='../results/models')\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wsn_ids.models.evaluate import evaluate_all, per_class_report, cross_validate_model\n",
    "\n",
    "summary, details = evaluate_all(models, X_test, y_test)\n",
    "print('\\nModel Summary:')\n",
    "summary[['model', 'accuracy', 'precision', 'recall', 'f1_score', 'false_positive_rate', 'energy_impact']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_name = summary.iloc[0]['model']\n",
    "best_pred = details[best_name]['y_pred']\n",
    "print(f'Best model: {best_name}')\n",
    "print('\\nPer-class classification report:')\n",
    "per_class_report(y_test, best_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross-validation on best model\n",
    "X_all = np.vstack([X_train, X_test])\n",
    "y_all = np.concatenate([y_train, y_test])\n",
    "\n",
    "print(f'Running 5-fold CV on {best_name} ...')\n",
    "cv_df = cross_validate_model(models[best_name], X_all, y_all)\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Result Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wsn_ids.visualization.plots import (\n",
    "    plot_confusion_matrix,\n",
    "    plot_model_comparison,\n",
    "    plot_feature_importance,\n",
    "    plot_roc_curves,\n",
    "    plot_energy_impact,\n",
    "    plot_cv_scores,\n",
    "    plot_pca_scatter,\n",
    ")\n",
    "\n",
    "plot_model_comparison(summary, save_dir='../results/plots')\n",
    "plot_energy_impact(summary, save_dir='../results/plots')\n",
    "plot_cv_scores(cv_df, best_name, save_dir='../results/plots')\n",
    "plot_confusion_matrix(y_test, best_pred, model_name=best_name, save_dir='../results/plots')\n",
    "plot_roc_curves(models[best_name], X_test, y_test, model_name=best_name, save_dir='../results/plots')\n",
    "plot_pca_scatter(X_all, y_all, save_dir='../results/plots')\n",
    "\n",
    "# Feature importance for Random Forest\n",
    "rf = models['Random Forest']\n",
    "plot_feature_importance(\n",
    "    rf.feature_importances_, feature_cols,\n",
    "    model_name='Random Forest', save_dir='../results/plots'\n",
    ")\n",
    "\n",
    "print('All result plots saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Real-Time Inference Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wsn_ids.ids import WSNIDS\n",
    "\n",
    "# Build a WSNIDS instance backed by already-trained models\n",
    "ids = WSNIDS(results_dir='../results')\n",
    "ids.df = df\n",
    "ids.models = models\n",
    "ids.feature_cols = feature_cols\n",
    "ids.best_model_name = best_name\n",
    "\n",
    "scenarios = [\n",
    "    ('Healthy Sensor',     [0.95, 0.04,  65.0,  5, 0.04,  2.5, 310]),\n",
    "    ('Suspected Sinkhole', [0.52, 0.48,  70.0, 15, 0.07,  4.0, 295]),\n",
    "    ('Suspected Sybil',    [0.82, 0.18,  58.0, 32, 0.11,  9.5, 305]),\n",
    "    ('Suspected DoS',      [0.28, 0.72,  18.0,  6, 0.58,  9.2,  20]),\n",
    "    ('Hello Flood',        [0.76, 0.24,  38.0, 20, 0.48, 13.0,  30]),\n",
    "    ('Selective Forward',  [0.35, 0.65,  55.0,  5, 0.05,  3.0, 300]),\n",
    "    ('Node Compromise',    [0.60, 0.50,  48.0,  9, 0.38,  8.0, 250]),\n",
    "]\n",
    "\n",
    "for name, obs in scenarios:\n",
    "    print(f'\\nNode: {name}')\n",
    "    print(f'  {ids.alert(obs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['model', 'accuracy', 'precision', 'recall', 'f1_score', 'false_positive_rate', 'energy_impact', 'inference_ms']\n",
    "summary[cols].style.highlight_max(\n",
    "    subset=['accuracy', 'f1_score', 'energy_impact'],\n",
    "    color='lightgreen'\n",
    ").highlight_min(\n",
    "    subset=['false_positive_rate', 'inference_ms'],\n",
    "    color='lightgreen'\n",
    ").format(precision=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
